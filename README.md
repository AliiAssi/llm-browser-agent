# ğŸ” LLM Browser Agent Prototype

A lightweight prototype that combines a high-speed LLaMA-4 model hosted on Groq with a web-enabled autonomous agent powered by [`browser-use`](https://github.com/chadwhitacre/browser-use). This system simulates a browsing assistant that can research topics in real time and return coherent, grounded answers.

---

## âš™ï¸ Features

- ğŸ§  Powered by [Meta LLaMA-4 Maverick 17B 128E](https://groq.com)
- ğŸŒ Agent uses synthetic browsing to research and synthesize information
- âš¡ Supports asynchronous execution via Python's `asyncio`
- ğŸ§ª Clean prototype setup â€“ ready for expansion

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/AliiAssi/llm-browser-agent.git
cd llm-browser-agent
```

### 2. Install Requirements
Make sure you have Python 3.8 or later installed.

```bash
pip install browser-use steel-sdk
```

### 3. Run the Prototype

```bash
python main.py
```

---

## ğŸ§ª Prototype Status

This is an **experimental prototype** to test the integration of real-time LLM querying with autonomous browsing. It is not production-ready but provides a strong starting point for future tools, agents, and search-based assistants.

---

## ğŸ“‹ Sample Output

```bash
> tell me about KamKalima

KamKalima is a digital Arabic language learning platform designed to support educators and students...
```

---

## ğŸ”§ Technologies Used

* ğŸ§  `ChatGroq` from `browser_use.llm`
* ğŸŒ `Agent` class for simulated web tasks
* ğŸŒ€ `asyncio` for asynchronous control flow
* ğŸ§° Optional: `steel-sdk` for extended tool support

---

## ğŸ‘¤ Author

**Ali Assi**  
[LinkedIn](https://linkedin.com/in/aliassii) Â· [GitHub](https://github.com/AliiAssi)

---

## ğŸ’¡ Inspiration

This project explores the idea of *autonomous LLM agents* that use search capabilities to complete real-world research tasks. Inspired by the possibilities of integrating LLMs with modular agent toolkits and Groq's high-throughput inference.